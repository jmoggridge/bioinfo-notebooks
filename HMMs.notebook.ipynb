{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models 1: Viterbi algorithm and outcome likelihood\n",
    "\n",
    "*JA. Moggridge*\n",
    "\n",
    "This notebook presents Python implementations of algorithms in chapter 10 of [Bioinformatics Algortithms by Pevzner and Compeau](https://www.bioinformaticsalgorithms.org/bioinformatics-chapter-10). With accompanying sample problems from [Rosalind](http://rosalind.info/problems/list-view/?location=bioinformatics-textbook-track) (BA10 problems). \n",
    "\n",
    "\n",
    "#### Introduction to biological HMMs and Viterbi algorithm\n",
    "  1. Computing the probability of a hidden path π, given an HMM  \n",
    "  2. Computing the probability of an emission string, given a hidden path π  \n",
    "  3. The decoding problem and Viterbi algorithm   \n",
    "  4. Outcome likelihood problem for HMMs   \n",
    "    \n",
    "This notebook covers the basic outline of HMMs for sequence analysis and how to compute the probabilities of emitted strings and hidden paths, given an existing HMM.   \n",
    "Creating profile HMMs, Viterbi learning, parameter estimation, Forward-Backward algorithm, and Baum-Welch learning are outlined in the next notebook.\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "## 1. Compute the probability of a hidden path π \n",
    "\n",
    "http://rosalind.info/problems/ba10a/\n",
    "\n",
    "\n",
    "- **Given**: \n",
    "    A hidden path $π$ followed by the states *States* and transition matrix *Transition* of an HMM (Σ, States, Transition, Emission). (There is no emission matrix in this example; just a Markov chain of states)\n",
    "\n",
    "- **Return**: \n",
    "    The probability of this path, $Pr(π)$. You may assume that initial probabilities are equal.  \n",
    "\n",
    "**Sample data**:\n",
    "\n",
    "        AABBBAABABAAAABBBBAABBABABBBAABBAAAABABAABBABABBAB\n",
    "        --------\n",
    "        A B\n",
    "        --------\n",
    "            A\tB\n",
    "        A\t0.377\t0.623\n",
    "        B\t0.26\t0.74\n",
    "\n",
    "        Sample Output\n",
    "        5.01732865318e-19\n",
    "\n",
    "<br> \n",
    "\n",
    "#### **Algorithm**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## calculate proability using the 'product rule' for each transition \n",
    "\n",
    "def prob_hiddenpath(hidden_path, T_matrix, states):\n",
    "    \"\"\"Calculates the probability of a hiddenpath given a T_matrix HMM\"\"\"\n",
    "    \n",
    "    # Hidden path symbols: encode as integers corresponding to their E, T matrix indices\n",
    "    hidden_path = [int(states.index(state)) for state in hidden_path]\n",
    "\n",
    "    # assuming all transitions from the initial state occur with equal probability.\n",
    "    prob = 0.5\n",
    "    prev = hidden_path[0]\n",
    "    for state in hidden_path[1:]:\n",
    "        trans_pr = T_matrix[prev][state]\n",
    "        prob = prob * trans_pr\n",
    "        prev = state\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Solved example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of the hidden path π: 5.017328653175628e-19\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pi = 'AABBBAABABAAAABBBBAABBABABBBAABBAAAABABAABBABABBAB'\n",
    "states = ['A', 'B']\n",
    "T_matrix = [[0.194, 0.806], [0.273, 0.727]]\n",
    "\n",
    "prob_pi = prob_hiddenpath(pi, T_matrix, states)\n",
    "print(\"probability of the hidden path π:\", prob_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Compute the probability of an outcome, given a hidden path and HMM\n",
    "\n",
    "<br>\n",
    "\n",
    "Assuming we already now the states of the hidden path, finding the probability of the emitted string simply requires using the product rule on the emission probabilities.\n",
    "\n",
    "http://rosalind.info/problems/ba10b/\n",
    "\n",
    "- **Given**: A string x, followed by the alphabet from which x was constructed, followed by a hidden path π, followed by the states States and emission matrix Emission of an HMM (Σ, States, Transition, Emission).\n",
    "\n",
    "\n",
    "- **Return**: The conditional probability Pr(x|π) that x will be emitted given that the HMM follows the hidden path π.\n",
    "\n",
    "**Sample data**:\n",
    "\n",
    "            zzzyxyyzzx                    # emission string x\n",
    "            --------\n",
    "            x y z                         # emission alphabet\n",
    "            --------\n",
    "            BAAAAAAAAA                    # hiddenpath pi\n",
    "            -------- \n",
    "            A B                           # hidden States\n",
    "            --------\n",
    "                x\ty\tz\n",
    "            A\t0.176\t0.596\t0.228\n",
    "            B\t0.225\t0.572\t0.203     # Emission matrix\n",
    "\n",
    "\n",
    "        Sample Output:\n",
    "\n",
    "            3.59748954746e-06\n",
    "            \n",
    "#### **Algorithm** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_emissions(emissions, alphabet, hidden_path, states, e_matrix):\n",
    "    \"\"\" calculate probability of this emission string given that hidden_path and Emission matrix \"\"\"\n",
    "    # encode emission and state symbols as integers\n",
    "    hidden_path = [int(states.index(state)) for state in hidden_path]\n",
    "    emissions = [int(alphabet.index(em)) for em in emissions]\n",
    "    probability = 1\n",
    "    \n",
    "    # using 'product rule'\n",
    "    for i in range(len(emissions)):\n",
    "        probability = probability * E_matrix[hidden_path[i]][emissions[i]]\n",
    "    \n",
    "    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Solved example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probability of emitted string, given HMM and hidden path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.5974895474624624e-06"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emissions = \"zzzyxyyzzx\"\n",
    "alphabet = ['x','y','z']\n",
    "pi = \"BAAAAAAAAA\" \n",
    "states = ['A','B']\n",
    "E_matrix = np.array([[0.176, 0.596, 0.228], [0.225, 0.572, 0.203]])\n",
    "   \n",
    "print('\\nProbability of emitted string, given HMM and hidden path')\n",
    "p_emissions(emissions, alphabet, pi, states, E_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 3. The decoding problem and solving using the Viterbi algorithm\n",
    "\n",
    "http://rosalind.info/problems/ba10c/\n",
    "\n",
    "- **Given**: A string x, followed by the alphabet Σ from which x was constructed, followed by the states States, transition matrix Transition, and emission matrix Emission of an HMM (Σ, States, Transition, Emission).\n",
    "\n",
    "-  **Return**: A path that maximizes the (unconditional) probability Pr(x, π) over all possible paths π.\n",
    "\n",
    "**Sample Dataset**\n",
    "\n",
    "        xyxzzxyxyy\n",
    "        --------\n",
    "        x   y   z\n",
    "        --------\n",
    "        A   B\n",
    "        --------\n",
    "            A   B\n",
    "        A   0.641   0.359\n",
    "        B   0.729   0.271\n",
    "        --------\n",
    "            x   y   z\n",
    "        A   0.117   0.691   0.192   \n",
    "        B   0.097   0.42    0.483\n",
    "        \n",
    "        Sample Output:\n",
    "        AAABBAAAAA\n",
    "    \n",
    "**Algorithm**\n",
    "\n",
    "- Create a graph data structure with |states| rows & |emissions| columns representing all possible hidden paths (Viterbi graph/matrix/Manhattan ). Add silent 'source' and 'sink' states with edges to all states in the first and last columns of the Viterbi graph.\n",
    "- From source to sink, fill in each node of the Viterbi matrix with the maximum product weight of incoming edges to each node. \n",
    "  - Edge weights are the product of probability of the previous state, state transition probability, and emission probability; take the maximum weight over all incoming edges.\n",
    "- Use dynamic programming to compute the largest product weight of probabilities to each node from source to sink; store backpointers to retrace the hidden path π.   \n",
    "- Backtrack from the final column state with the greatest probability to decode the maximum-likelihood hidden path given the HMM and emission string.\n",
    "- Use log-transformed transition and emission matrices to prevent underflow (numbers get too small for float data-type when emission string is large). Use logs and addition instead of multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def viterbi_algorithm(emission, T, E, states, alphabet):\n",
    "    \"\"\"returns max likelihood hidden path for emission string, given HMM\"\"\"\n",
    "    \n",
    "    S = len(states)\n",
    "    n = len(emission)\n",
    "    # initialize Viterbi graph and backpointers matrices\n",
    "    viterbi = np.ones(shape = (S, n)) * -float('inf')\n",
    "    pointers = [[False for e in range(n)] for s in range(S)] \n",
    "    \n",
    "    # initialize first column of viterbi with: weight(node) = (Pr_emission)*(1/States)\n",
    "    for state in range(S):\n",
    "        viterbi[state][0] = np.log(1/S) + E[state][emission[0]]\n",
    "        pointers[state][0] = -1\n",
    "        \n",
    "    # Fill viterbi graph using dynamic programming\n",
    "    for i in range(1,n):\n",
    "        for state in range(S):\n",
    "            for prev in range(S):\n",
    "                p_total = E[state][emission[i]] + T[prev][state] + viterbi[prev][i-1]\n",
    "                # find max-weight path to current node\n",
    "                if p_total > viterbi[state][i]:\n",
    "                    viterbi[state][i] = p_total\n",
    "                    pointers[state][i] = prev\n",
    "                    \n",
    "    # start backtrack from max-likelihood state in last column of viterbi graph\n",
    "    score = -float('inf')\n",
    "    for state in range(S):\n",
    "        if viterbi[state][n-1] > score:\n",
    "            last = state\n",
    "            score = viterbi[state][n-1]\n",
    "    path = [last]\n",
    "    \n",
    "    # backtrack to recreate max likelihood hidden_path in reverse\n",
    "    i = n-1\n",
    "    while i > 0:\n",
    "        next = pointers[last][i]\n",
    "        path.append(next)\n",
    "        last = next\n",
    "        i -= 1\n",
    "    # reverse string to get hidden_path solution to decoding problem\n",
    "    return ''.join(str(states[state]) for state in path[::-1])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solved example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse Rosalind HMMs input data\n",
    "## Use log-transform to prevent underflow\n",
    "\n",
    "def parse_HMM(lines):\n",
    "    emission = lines[0].strip()\n",
    "    alphabet = lines[2].strip().split()\n",
    "    emission = [int(alphabet.index(em)) for em in emission]\n",
    "    states = lines[4].strip().split()\n",
    "    S = len(states)\n",
    "    T = np.array([line.split()[1:] for line in lines[7:7+S]], float)\n",
    "    T = np.log(T)\n",
    "    E = np.array([line.split()[1:] for line in lines[9+S:]], float)\n",
    "    E = np.log(E)\n",
    "    return(emission, alphabet, states, T, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emitted: [0, 1, 0, 2, 2, 0, 1, 0, 1, 1] \n",
      "Alphabet ['x', 'y', 'z'] States ['A', 'B'] \n",
      "E_matrix\n",
      " [[-2.14558134 -0.36961546 -1.65025991]\n",
      " [-2.3330443  -0.86750057 -0.72773863]] \n",
      "T_matrix\n",
      " [[-0.44472582 -1.02443289]\n",
      " [-0.31608155 -1.30563646]]\n",
      "\n",
      "Decoded path π = AAABBAAAAA\n"
     ]
    }
   ],
   "source": [
    "## Sample data1:\n",
    "with open(\"./data/10c_test.txt\") as f:\n",
    "    lines = [line.strip() for line in f]\n",
    "emission, alphabet, states, T, E = parse_HMM(lines)\n",
    "decoded_pi = viterbi_algorithm(emission, T, E, states, alphabet)\n",
    "print('Emitted:', emission,'\\nAlphabet', alphabet,'States',states,\n",
    "      '\\nE_matrix\\n', E, '\\nT_matrix\\n', T)\n",
    "print('\\nDecoded path π =', decoded_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## 4. Outcome Likelihood Problem\n",
    "\n",
    "What is the likelihood of a particular emitted string from any hidden path, given an HMM?\n",
    "\n",
    "**Given**: A string x, followed by the alphabet Σ from which x was constructed, followed by the states States, transition matrix Transition, and emission matrix Emission of an HMM (Σ, States, Transition, Emission).\n",
    "\n",
    "**Return**: The probability Pr(x) that the HMM emits x.\n",
    "\n",
    "**Sample Dataset**\n",
    "\n",
    "        xzyyzzyzyy\n",
    "        --------\n",
    "        x   y   z\n",
    "        --------\n",
    "        A   B\n",
    "        --------\n",
    "            A   B\n",
    "        A   0.303   0.697 \n",
    "        B   0.831   0.169 \n",
    "        --------\n",
    "            x   y   z\n",
    "        A   0.533   0.065   0.402 \n",
    "        B   0.342   0.334   0.324\n",
    "        \n",
    "        Sample Output\n",
    "            1.1005510319694847e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Algorithm\n",
    "\n",
    "def outcome_likelihood(emission, T, E, states): # outcome-likelihood of HMM emitting emissions (sum of all hidden paths)\n",
    "    \"\"\"returns likelihood of emission string, given HMM\"\"\"\n",
    "\n",
    "    S = len(states)\n",
    "    n = len(emission)\n",
    "    viterbi = np.zeros(shape = (S, n))\n",
    "\n",
    "    # init first column of viterbi with Pr_emission & 1/States\n",
    "    for state in range(S):\n",
    "        viterbi[state][0] = 1/S * E[state][emission[0]]\n",
    "\n",
    "    # Fill viterbi graph with sums over all incoming edges for ea node\n",
    "    for i in range(1,n):\n",
    "        for state in range(S):\n",
    "            em = E[state][emission[i]]\n",
    "            for prev in range(S):\n",
    "                trans = T[prev][state]\n",
    "                viterbi[state][i] += trans * em * viterbi[prev][i-1]\n",
    "    return sum(viterbi[s][n-1] for s in range(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string: [0, 2, 1, 1, 2, 2, 1, 2, 1, 1] \n",
      "states ['A', 'B'] \n",
      "\n",
      "E_matrix\n",
      " [[0.533 0.065 0.402]\n",
      " [0.342 0.334 0.324]] \n",
      "\n",
      "T_matrix\n",
      " [[0.303 0.697]\n",
      " [0.831 0.169]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1005510319694845e-06"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open(\"./data/10d_test.txt\") as f:\n",
    "    lines = [line.strip() for line in f]\n",
    "    emission, alphabet, states, T, E = parse_HMM(lines)\n",
    "    T = np.exp(T)\n",
    "    E = np.exp(E)\n",
    "\n",
    "    print('string:', emission,'\\nstates',states,'\\n\\nE_matrix\\n',E, '\\n\\nT_matrix\\n', T)\n",
    "\n",
    "\n",
    "outcome_likelihood(emission, T, E, states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
